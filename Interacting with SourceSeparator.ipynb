{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18b1c1-4424-4025-98c1-eb41a932dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import  DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ccda5-6e5d-41aa-9a65-6174e3c9218d",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c873904-fadb-40ce-a1ea-c757b726a1b1",
   "metadata": {},
   "source": [
    "The notebook assumes the data uses the following file structure\n",
    "- Data\n",
    "    -  train\n",
    "    -  val\n",
    "    -  test\n",
    "    -  all_ir (contains full set of irs used for data augmentation)\n",
    "\n",
    "The train validation and test folders have the following subfolders\n",
    "- ir: the irs used to augment the data within the directory\n",
    "- mix_clean: two speaker mixtures\n",
    "- mix_noise: two speaker mixtures with additive noise\n",
    "- s1: first set of source speakers in the mixtures\n",
    "- s2: second set of source speakers in the mixtures\n",
    "\n",
    "The mixtures share filenames with the sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4439ec2-1635-4086-be5d-f023d7d03c2a",
   "metadata": {},
   "source": [
    "## Impulse Response Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4785f1-3ce9-4f2b-ae05-171d90aee730",
   "metadata": {},
   "source": [
    "The following functions and commented code can be used to create a set of training and evaluation impulse responses. IRs are copied to the ir sub folders. This method was picked to leverage the torch audio-mentation object ApplyImpulseResponse. impulse responses are randomly selected.\n",
    "\n",
    "All IRs are from the MIT McDermott survey data https://mcdermottlab.mit.edu/Reverb/IR_Survey.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09236317",
   "metadata": {},
   "source": [
    "Uncomment the following cell block to create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e13a4-343f-4a87-aab9-603057bbb90c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#from sourcesep.utilities.utils import split_ir_files, copy_ir_files\n",
    "\n",
    "# train_ir_dir = './Data/train/ir'\n",
    "# test_ir_dir = './Data/test/ir'\n",
    "# val_ir_dir = './Data/val/ir'\n",
    "# source_ir_dir = './Data/all_ir'\n",
    "\n",
    "# ir_split = split_ir_files(\"./Data/all_ir\", .15, .15)\n",
    "# train_ir_names = ir_split['train']\n",
    "# test_ir_names = ir_split['test']\n",
    "# val_ir_names = ir_split['val']\n",
    "\n",
    "# copy_ir_files(source_ir_dir,train_ir_dir,train_ir_names)\n",
    "\n",
    "# copy_ir_files(source_ir_dir,test_ir_dir,test_ir_names)\n",
    "\n",
    "# copy_ir_files(source_ir_dir,val_ir_dir,val_ir_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f1ccf-0543-487c-940c-c80b304e16a2",
   "metadata": {},
   "source": [
    "## Audio DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bfa33-a5f3-4f1e-8c7d-989b51d1ce1a",
   "metadata": {},
   "source": [
    "Pytorch dataset used to load the audio clip. Audio files are loaded as batches are called due to limitations in jupyterlab memory. Upon loading, random cropping is applied.\n",
    "\n",
    "apply_ir = True will apply a random impulse response to the input data prior to fourier transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.dataset import SourceSepDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10d2ce-3321-42d6-a3c1-04a67ea9cb13",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868abf-7f31-4277-a406-a7f7f523b333",
   "metadata": {},
   "source": [
    "I approached the problem of noisy reverberant speaker speration in two stages. The first network attempts to simultaneously de-reverberate and de-noise an input mixture of two speakers. The second network splits the speaker mixture into channels containing the different speakers.\n",
    "\n",
    "The aim is to assess whether a speech enhancement network can help the time domain source separator generalize to noisy reverberant audio. For the sake of project scope, the implementations are limited to single channel, two speaker mixtures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88e46b-3b42-4c45-ac06-1d09ed0e8588",
   "metadata": {},
   "source": [
    "## Complex SkipConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b3c12-9ebc-4185-984b-2b58b43a1324",
   "metadata": {},
   "source": [
    "The following network architecture called in the import is based on the U-Net architecture described in Kothapally et al., 2020. The network is a U-net with convolutional skip networks that process the intermediate representations by the encoder.\n",
    "\n",
    "The primary difference between the paper and this network is that this implementation is a complex-valued U-Net that produces masks that directly apply the real and imaginary parts of the STFT coeficients. Complex batch normalization, convolution, transpose convolution, and activation functions are all implemented as described in Trabelsi et al. (2018)\n",
    "\n",
    "The model also deviates from the design in the Kothapally paper in the output. The original network learns to synthesize an enhanced spectrogram, while in this implementation, the network produces two masks that are applied to the input STFT to scale the real and imaginary parts of the coefficients. The justification is that this decreases the amount of training that is needed to produce outputs that are meaningful to the source separator. The method for producing complex masks mimics Ephrat et al. (2018 although a tanh activation function is used instead of a sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462067d-6340-43cd-8320-caf913a028c9",
   "metadata": {},
   "source": [
    "I chose to implement this model as a complex network as opposed to a real-valued network that is applied to spectrograms, as phase does not need to be discarded when training. This technique allows us to avoid the use of additional techniques to learn, reconstruct, or incorporate the phase from the noisy reverberant mixture into the spectrogram that would be produced by a real-valued network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71085151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.enhancer.model import ComplexSkipConvNet\n",
    "\n",
    "#network parameter sets\n",
    "\n",
    "#large model with halved channel count/skip block count\n",
    "enc_params = [{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([1,2]) ,'out_ch':32, 'sk_bl':8}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]) ,'out_ch':64, 'sk_bl':8}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]) ,'out_ch':128,'sk_bl':4}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':256,'sk_bl':4}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':256,'sk_bl':2}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':256,'sk_bl':2}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':256,'sk_bl':1}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':256,'sk_bl':0}]\n",
    "\n",
    "dec_params = [{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]), 'op':torch.tensor([0,0]) ,'out_ch':256}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':256}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':256}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':256}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':128}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':64}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':32}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([1,0]), 'out_ch':1}]\n",
    "\n",
    "skip_params = {'k':3, 'p':1, 's':1}\n",
    "\n",
    "unet_params_large = {'enc':enc_params, 'dec': dec_params,'sk':skip_params}\n",
    "\n",
    "#small network\n",
    "enc_params = [{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([1,2]) ,'out_ch':16, 'sk_bl':8}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]) ,'out_ch':32, 'sk_bl':8}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]) ,'out_ch':32,'sk_bl':4}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':64,'sk_bl':4}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':64,'sk_bl':2}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':64,'sk_bl':2}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':128,'sk_bl':1}\n",
    "              ,{'k':torch.tensor([5,5]), 's':torch.tensor([2,2]), 'p': torch.tensor([2,2]), 'out_ch':128,'sk_bl':0}]\n",
    "\n",
    "dec_params = [{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]), 'op':torch.tensor([0,0]) ,'out_ch':128}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':64}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':64}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':64}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':32}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':32}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([0,0]), 'out_ch':16}\n",
    "              ,{'k':torch.tensor([2,2]), 's':torch.tensor([2,2]),'op':torch.tensor([1,0]), 'out_ch':1}]\n",
    "\n",
    "skip_params = {'k':3, 'p':1, 's':1}\n",
    "\n",
    "unet_params = {'enc':enc_params, 'dec': dec_params,'sk':skip_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528c25e-e8d4-4a14-ad78-700d2d3e62cf",
   "metadata": {},
   "source": [
    "## Conv TasNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dddedf-004e-4844-b902-64595964978c",
   "metadata": {},
   "source": [
    "The following code called in the import is a non-causal, two speaker specific implementation of the convolational TaS net proposed in (Luo, Mesgarani, 2018)\n",
    "\n",
    "Network hyperparameters are taken directly from the small versions of the model that were assesed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.separator.model import ConvTasNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb574b-d9cb-4409-8b67-326e71574420",
   "metadata": {},
   "source": [
    "## Joint Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff54ff7-0dd6-48d0-ab9c-6efa93993f4d",
   "metadata": {},
   "source": [
    "The two models are combined for into a single object for ease in joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.jointmodel import SourceSeparator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0227752-db21-4f0f-9fe4-87d1015e3554",
   "metadata": {},
   "source": [
    "## Model Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2d5cb-2aed-4ca0-9a0a-805a56809584",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#  CTN: 1.5 million params , larger models cause cuda issues\n",
    "# model = ConvTasNet()\n",
    "\n",
    "# #Default CUNET: 3.4 million params\n",
    "# model = ComplexSkipConvNet(unet_params)\n",
    "\n",
    "# #default joint network 5.1 m params\n",
    "# model = SourceSeparator(unet_params, sep_net=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b034d81-d4c4-45ee-84c6-3278e9bc44a2",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343fbbdb-bb83-4939-adf2-6f9e67db79ff",
   "metadata": {},
   "source": [
    "The objective function used in training is the scale-invariant source-to-noise ratio described in Luo 2018. This objective is used to measure loss for both the source separator as well as the U-Net (measured using the sensitivity of the output).\n",
    "\n",
    "As the scope of the project is limited to two speaker mixtures, the loss calculation can be grouped into two categories. \n",
    "\n",
    "The enhancer outputs a single channel, so SI-SNR is simply a measure of the error between the target signal and the predicted signal that accounts for the scale of the signal.\n",
    "\n",
    "The source separator produces two channels for each input signal, which can lead to complications as the network would also need to learn the order of the target single speaker signals. Permutation invariance is accounted for by considering the parwise SI-SNR values between the predicted channels and the ground truth sources. The permutation of predictions and labels that maximizes the objective is used as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c727c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.loss import si_snr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855d05c-3c72-4e97-b29b-475ecb451fa5",
   "metadata": {},
   "source": [
    "# Train and Evaluation Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb188d01-5fcd-424b-8570-86c19c8e17bd",
   "metadata": {},
   "source": [
    "Two source separation systems were compared\n",
    "\n",
    "The first uses both networks, the second system is just the tasnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d02c7-d4d6-4fe3-a60d-6da2a8aff041",
   "metadata": {},
   "source": [
    "The joint system is trained in two stages: general training and then fine tuning. The first phase defines loss as the aggregate of the SI-SNR for the reconstructed signal produced by the u-net and the clean speaker mixture and the SI-SNR for the source separator and the clean speaker channels.\n",
    "\n",
    "The approach aims to encourage the u-net to learn intermediate representations that are helpful in the speech enhancement task while also encouraging the network to learn the overarching goal of the system.\n",
    "\n",
    "For fine tuning, all network layers of the u-net besides the output layer are frozen. The loss term is just the SI-SNR between the source separator output and the clean single speaker sources.\n",
    "\n",
    "The aim of the second phase is to maximize the performance of the final output of the system and allow the u-net to learn high-level changes to its output that benefit overall source separation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28617cc7-5e13-4012-8398-fe444a09d513",
   "metadata": {},
   "source": [
    "A tasnet is also trained as a baseline for the same number of epochs as the joint model to see if the speech enhancement network aids in the source separation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.train import train, evaluate, train_ss, evaluate_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8634e-7f15-42f6-89f1-ea2feb2a5d65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNet Only Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed247d3d-82bf-4c57-8f12-5f80ace57d87",
   "metadata": {},
   "source": [
    "Used for intial Unet testing. Not used in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc5ff6-9877-43ae-97d0-70e996fa4a4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = SourceSepDS('./Data/train', sep_net=True, ir_p=1, rand_crop=True)\n",
    "val_ds = SourceSepDS('./Data/val', sep_net=True, ir_p=1, rand_crop=False, ir_determ=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d0d54-0b17-412d-94cd-a5197d6759d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = SourceSeparator(unet_params, sep_net=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f94e32-5333-4bb5-9f2b-6cf79b055dde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#load file\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model_file_name = 'testnew'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ebd44-abe3-4e96-9c23-e9cef5f6e852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.5, patience=1)\n",
    "criterion = si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01f0a1-70a7-45fb-969e-e8c1169ad9d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "_,_,_,_ = train(epochs\n",
    "                  ,model \n",
    "                  ,criterion\n",
    "                  ,optimizer\n",
    "                  ,scheduler\n",
    "                  ,train_dataloader\n",
    "                  ,val_dataloader\n",
    "                  ,device\n",
    "                  ,save_dir='./models/testnew.pkl'\n",
    "                  ,valid_freq=1\n",
    "                  ,fine_tune=False\n",
    "                  ,batch_eval=500\n",
    "                  ,batch_loud=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47faeaf2-d472-418d-8ce2-a15108463517",
   "metadata": {},
   "source": [
    "## Joint Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3011b0-d864-4899-bae4-0f43bb3f9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = SourceSepDS('./Data/train',sep_net=True, ir_p=1, rand_crop=True, ir_determ=False)\n",
    "val_ds = SourceSepDS('./Data/val',sep_net=True, ir_p=1, rand_crop=False, ir_determ=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38236a-8577-4b18-897f-249f122405c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = SourceSeparator(unet_params, sep_net=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3cee5-8046-4cd1-98cc-f46746390aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model_file_name = 'joint_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5750be-d238-43f3-8e84-0dec7a984d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.5, patience=1)\n",
    "criterion = si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a6b8-fcf2-4261-8317-a6ec3e28036a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "train_losses, valid_losses, train_si_snris, valid_si_snris = train(epochs\n",
    "                                                                      ,model \n",
    "                                                                      ,criterion\n",
    "                                                                      ,optimizer\n",
    "                                                                      ,scheduler\n",
    "                                                                      ,train_dataloader\n",
    "                                                                      ,val_dataloader\n",
    "                                                                      ,device\n",
    "                                                                      ,save_dir='./models/joint_final.pkl'\n",
    "                                                                      ,valid_freq=4\n",
    "                                                                      ,fine_tune=False\n",
    "                                                                      ,batch_eval=500\n",
    "                                                                      ,batch_loud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab585f24-8b30-492d-879d-e6e2189aef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_tl = train_losses\n",
    "joint_vl = valid_losses\n",
    "joint_tsisnri = train_si_snris\n",
    "joint_vsisnri = valid_si_snris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c12a3-bea8-48b9-b205-e1f19f68f440",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f38a3-c4c3-4b46-9be4-4005c7d288e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = SourceSepDS('./Data/train',sep_net=True, ir_p=1, rand_crop=True, ir_determ=False)\n",
    "val_ds = SourceSepDS('./Data/val',sep_net=True, ir_p=1, rand_crop=False, ir_determ=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acea8f4-c102-4bb4-ba1c-b0c666bd661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = SourceSeparator(unet_params, sep_net=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f040cd-1e38-4640-bd2d-7b734e0fdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'joint_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f2056-6b46-4c94-84c0-f4f57ba93145",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.5, patience=1)\n",
    "criterion = si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362c2d5-ecd8-4fa6-9a0e-362cf6f9bb05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "train_losses, valid_losses, train_si_snris, valid_si_snris = train(epochs\n",
    "                                                                  ,model \n",
    "                                                                  ,criterion\n",
    "                                                                  ,optimizer\n",
    "                                                                  ,scheduler\n",
    "                                                                  ,train_dataloader\n",
    "                                                                  ,val_dataloader\n",
    "                                                                  ,device\n",
    "                                                                  ,save_dir='./models/joint_final.pkl'\n",
    "                                                                  ,valid_freq=2\n",
    "                                                                  ,fine_tune=True\n",
    "                                                                  ,batch_eval=200\n",
    "                                                                  ,batch_loud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c4b39-1f31-4f4d-bfcf-f83efc205339",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_tl = train_losses\n",
    "ft_vl = valid_losses\n",
    "ft_tsisnri = train_si_snris\n",
    "ft_vsisnri = valid_si_snris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61664c31-7fee-458d-b0b3-33fa5026dbd7",
   "metadata": {},
   "source": [
    "## Baseline Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace7fbe-3d0c-4288-af8c-c79a16bddbff",
   "metadata": {},
   "source": [
    "Training and evaluation loops for only the source separation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77e3e6-e29f-4768-9eb7-9eef922a1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = SourceSepDS('./Data/train', sep_net=True, ir_p=1, rand_crop=True, ir_determ=False )\n",
    "val_ds = SourceSepDS('./Data/val', sep_net=True, ir_p=1, rand_crop=False, ir_determ=True )\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c831b-026b-4e50-9ceb-3fe1d921edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "bl_model = ConvTasNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce78c0-ba93-42a5-824b-c4e02fc5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model:\n",
    "    model_file_name = 'baseline_large_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    bl_model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b034616-1dac-49d8-81bd-da61f2ea9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(bl_model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.5, patience=1)\n",
    "criterion = si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a19137-7244-41a9-b8f1-cfe778aebd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "train_losses, valid_losses, train_si_snris, valid_si_snris = train_ss(epochs\n",
    "                                                                      ,bl_model \n",
    "                                                                      ,criterion\n",
    "                                                                      ,optimizer\n",
    "                                                                      ,scheduler\n",
    "                                                                      ,train_dataloader\n",
    "                                                                      ,val_dataloader\n",
    "                                                                      ,device\n",
    "                                                                      ,save_dir='./models/baseline_large_final.pkl'\n",
    "                                                                      ,valid_freq=2\n",
    "                                                                      ,batch_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680f692-60b6-42b5-bf45-91ae8b8ff73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_tl = train_losses\n",
    "bl_vl = valid_losses\n",
    "bl_tsisnri = train_si_snris\n",
    "bl_vsisnri = valid_si_snris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2914f6d-d14f-487a-a6bf-0ab6703cd995",
   "metadata": {},
   "source": [
    "# Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c43e2-45cc-45d8-872a-d5f6c91ce483",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b48e5-1eab-40a2-9ae6-a9dd588d9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load join net \n",
    "model = SourceSeparator(unet_params, sep_net=True).to(device)\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'joint_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef36323-e08b-4e9d-a2c4-48d11d9d103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SourceSepDS('./Data/test', sep_net=True, ir_p=1, rand_crop=False, ir_determ=True )\n",
    "test_dataloader = DataLoader(test_ds, batch_size)\n",
    "\n",
    "joint_loss_test, joint_si_snri_test, joint_si_snri_dn_test = evaluate(model, test_dataloader, criterion, device, batch_eval=1000, fine_tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e7d56-d2ea-43ba-999e-63df393eb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint Net si snri: {}'.format(joint_si_snri_test))\n",
    "print('Denoiser si snri: {}'.format(joint_si_snri_dn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3c739-9bc7-412f-9db8-406385f74496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load baseline\n",
    "bl_model = ConvTasNet().to(device)\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'baseline_large_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    bl_model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc862a3-49a9-42d6-9e23-847a0c52ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SourceSepDS('./Data/test', sep_net=True, ir_p=1, rand_crop=False, ir_determ=True )\n",
    "test_dataloader = DataLoader(test_ds, batch_size)\n",
    "\n",
    "bl_loss_test, bl_si_snri_test = evaluate_ss(bl_model, test_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c6fde-c6e0-460d-aca5-7c34efae9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tasnet si snri: {}'.format(bl_si_snri_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbf096-489a-4bd3-a09b-50c4213ec8c6",
   "metadata": {},
   "source": [
    "Out of curiosity, evaluating the joint network before fine tuning. This model is not included is in the upload as the total submssion would exceed the file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31afa2-3c87-4d1a-8594-142e3d6d1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load join net \n",
    "model = SourceSeparator(unet_params, sep_net=True).to(device)\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'joint_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f60576-ba44-4374-958d-76396418cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SourceSepDS('./Data/test', sep_net=True, ir_p=1, rand_crop=False, ir_determ=True )\n",
    "test_dataloader = DataLoader(test_ds, batch_size)\n",
    "\n",
    "joint_preft_loss_test, joint_preft_si_snri_test, joint_preft_si_snri_dn_test = evaluate(model, test_dataloader, criterion, device, batch_eval=1000, fine_tune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc942eea-15bf-4ced-81b5-33b433c7d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint Net si snri: {}'.format(joint_preft_si_snri_test))\n",
    "print('Denoiser si snri: {}'.format(joint_preft_si_snri_dn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fdb22-5834-43bc-a8ac-ffaab5806fcf",
   "metadata": {},
   "source": [
    "# Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sourcesep.utils import evaluate_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a723ff-1b27-4d24-931c-1db491864e50",
   "metadata": {},
   "source": [
    "## Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d85c1d-c073-4b4b-b84c-98d18e03ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load join net \n",
    "model = SourceSeparator(unet_params, sep_net=True).to(device)\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'joint_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47187a5-6d8d-48c6-833f-7359c10b3bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_filepath = 'normal-charlie.wav'\n",
    "\n",
    "evaluate_file(real_filepath, model, apply_ir=False, only_tas=False, save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270070e-a1e2-4646-a3d3-1301e7bca756",
   "metadata": {},
   "source": [
    "## TasNet Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e95d1-64ab-498d-8e2a-aa698f1cb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load baseline\n",
    "bl_model = ConvTasNet().to(device)\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model_file_name = 'baseline_large_final'\n",
    "    path_to_pkl = './models/{}.pkl'.format(model_file_name)\n",
    "    bl_model.load_state_dict(torch.load(path_to_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf0504-ba45-4f4a-8a5f-83901a54bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_filepath = 'normal-charlie.wav'\n",
    "\n",
    "evaluate_file(real_filepath, bl_model, apply_ir=False, only_tas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216179e-edeb-40e3-afc3-f501fd62310a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
